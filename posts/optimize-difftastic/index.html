<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>How do I boost difftastic by 4x | QuarticCat's Blog</title>
<meta name=keywords content="rust,optimization"><meta name=description content="Difftastic is a structural diff that understands syntax. The diff results it generates are very fancy, but its performance is poor, and it consumes a lot of memory. Recently, I boosted it by 4x while using only 23% of memory (#393, #395, #401). This post explains how I accomplished this. Hope it can bring you some inspiration.
When I started to write this post, not all optimizations were reviewed and merged."><meta name=author content="QuarticCat"><link rel=canonical href=https://blog.quarticcat.com/posts/optimize-difftastic/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://blog.quarticcat.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://blog.quarticcat.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://blog.quarticcat.com/favicon-32x32.png><link rel=apple-touch-icon href=https://blog.quarticcat.com/apple-touch-icon.png><link rel=mask-icon href=https://blog.quarticcat.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://blog.quarticcat.com/posts/optimize-difftastic/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script defer src=https://static.cloudflareinsights.com/beacon.min.js data-cf-beacon='{"token": "f4a0d5ded0bc48e19ea90f852a11cb57"}'></script><meta property="og:title" content="How do I boost difftastic by 4x"><meta property="og:description" content="Difftastic is a structural diff that understands syntax. The diff results it generates are very fancy, but its performance is poor, and it consumes a lot of memory. Recently, I boosted it by 4x while using only 23% of memory (#393, #395, #401). This post explains how I accomplished this. Hope it can bring you some inspiration.
When I started to write this post, not all optimizations were reviewed and merged."><meta property="og:type" content="article"><meta property="og:url" content="https://blog.quarticcat.com/posts/optimize-difftastic/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-10-06T00:00:00+00:00"><meta property="article:modified_time" content="2022-10-06T00:00:00+00:00"><meta property="og:site_name" content="QuarticCat's Blog"><meta name=twitter:card content="summary"><meta name=twitter:title content="How do I boost difftastic by 4x"><meta name=twitter:description content="Difftastic is a structural diff that understands syntax. The diff results it generates are very fancy, but its performance is poor, and it consumes a lot of memory. Recently, I boosted it by 4x while using only 23% of memory (#393, #395, #401). This post explains how I accomplished this. Hope it can bring you some inspiration.
When I started to write this post, not all optimizations were reviewed and merged."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.quarticcat.com/posts/"},{"@type":"ListItem","position":2,"name":"How do I boost difftastic by 4x","item":"https://blog.quarticcat.com/posts/optimize-difftastic/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"How do I boost difftastic by 4x","name":"How do I boost difftastic by 4x","description":"Difftastic is a structural diff that understands syntax. The diff results it generates are very fancy, but its performance is poor, and it consumes a lot of memory. Recently, I boosted it by 4x while using only 23% of memory (#393, #395, #401). This post explains how I accomplished this. Hope it can bring you some inspiration.\nWhen I started to write this post, not all optimizations were reviewed and merged.","keywords":["rust","optimization"],"articleBody":"Difftastic is a structural diff that understands syntax. The diff results it generates are very fancy, but its performance is poor, and it consumes a lot of memory. Recently, I boosted it by 4x while using only 23% of memory (#393, #395, #401). This post explains how I accomplished this. Hope it can bring you some inspiration.\nWhen I started to write this post, not all optimizations were reviewed and merged. But I will keep it updated.\nHow does difftastic work The official manual has a chapter describing its diff algorithm. Here’s my understanding:\nSay, we have two files. They are parsed to two syntax trees.\n------------------------- - A | - A - B | - B - C | - D - D | - E - E | - F We want to match them. To do this, we have two pointers to syntax nodes in two trees, respectively.\n------------------------- - A \u003c- | - A \u003c- - B | - B - C | - D - D | - E - E | - F In each step, we have some choices, and each of them represents a diff choice (an insertion, a deletion, unchanged, etc.). For example, here we can move both pointers by one node (pre-order traversal) since the nodes they point to are the same.\n- A ------------------------- - B \u003c- | - B \u003c- - C | - D - D | - E - E | - F Or we can move the left pointer by one node, which means a deletion.\n- - A ------------------------- - B \u003c- | - A \u003c- - C | - B - D | - D - E | - E | - F Or we can move the right pointer by one node, which means an insertion.\n+ - A ------------------------- - A \u003c- | - B \u003c- - B | - D - C | - E - D | - F - E | We keep moving pointers until finishing the traversal in both syntax trees. Then the moving path represents the diff result.\n- A - B - - C - D - E + - F Obviously, there are multiple paths. To find the best one, we abstract it as a shortest path problem: a vertex is a pointer pair, and an edge is a movement from one pointer pair to another. Edge lengths are manually defined based on our preferences. For example, it is preferable to see two identical nodes as unchanged rather than one insertion plus one deletion, therefore the length of the former is shorter.\n+-[1]-\u003e (B, B) -\u003e ... --+ | | (A, A) +-[9]-\u003e (B, A) -\u003e ... --+-\u003e (EOF, EOF) | | +-[9]-\u003e (A, B) -\u003e ... --+ This is a simplified illustration. In the actual code, there are more kinds of edges, and the vertices contain more information.\nYou don’t have to fully understand how it works internally to start optimizing. As long as your optimized code logically equals the previous one, it should be good. It is typical for your comprehension of the code to progressively advance throughout the optimization process. Of course, having a deeper understanding helps you identify more optimization opportunities.\nBenchmarking \u0026 profiling To perform optimization, you should first define a baseline, i.e., find a benchmark, and then profile it to locate hot spots and choose which code area merits your attention. Fortunately, the official manual also offers a chapter that covers all we need.\nIn addition, I used hyperfine with some warm-up runs to improve the accuracy and stability of the result. Here’s a document of LLVM that introduces some tips to reduce benchmarking noise. I didn’t use all of them at that time, because I just knew this webpage recently. :)\nThere are many excellent profiling tools. Examples include flamegraph, which can be used for more than just CPU metrics, and valgrind, which is especially useful for memory profiling.\nApart from those fancy tools, you can try commenting out some code pieces or adding useless fields to structs and then check the performance difference. This will quickly give you a rough estimate of the amount of profit you will gain from optimizing them. Valueless targets are not worth your attention.\nAnother trick is that you can print something into stderr and then filter them by \u003e/dev/null 2\u003e\u00261. Following that, you can do counting by | wc -l, or find the minimum / maximum value by | sort -n | head/tail -1. It’s sometimes more convenient than implementing the same functionality inside the program. You can use this trick to collect information like how frequently the control flow enters a code block.\nOptimizations Here comes the main dish. I will select several commits and describe what I have done.\nFree lunch Commits: 06b46e9\nThere are some free optimization approaches you can have a taste first. I call them “free” because applying them is effortless, you don’t even have to know about the code.\nLTO: In Rust, this can be enabled by a single line in Cargo.toml: lto = \"thin\" or \"fat\". As for C++, if you are using CMake, then passing -DCMAKE_INTERPROCEDURAL_OPTIMIZATION=ON should work.\nPGO: For Rust, I recommend cargo-pgo. For C++, you can follow instructions on Clang’s doc.\nBOLT\nPolly\nMemory Allocator: The default memory allocator usually performs badly. Better alternatives include {je,tc,mi,sn}malloc and maybe more.\nSimple simplifications Commits: d48ee2d, 3b0edb4, b88625d\nAccording to my profile results, most memory was used for storing the Vertex type. Any simplification of this type will result in a huge improvement. I discovered that one of its fields implemented Copy but was wrapped by RefCell, which was overkilled. Cell was just enough. Moreover, I found that the internal third-party Stack type had a lot of fields that were useless for this problem. It was a very simple functional stack, so I just wrote a new one to replace it.\nRefactor parent stack Commits: 2c6b706, 5e5eef2, b95c3a6\nThe original parent stack structure was obscure.\nstruct Vertex\u003c'a, 'b\u003e { // ... parents: Stack\u003cEnteredDelimiter\u003c'a\u003e\u003e, } enum EnteredDelimiter\u003c'a\u003e { PopEither((Stack\u003c\u0026'a Syntax\u003c'a\u003e\u003e, Stack\u003c\u0026'a Syntax\u003c'a\u003e\u003e)), PopBoth((\u0026'a Syntax\u003c'a\u003e, \u0026'a Syntax\u003c'a\u003e)), } | | |l| | | | |l| |r| | | | |l| |r| PopEither | | |----------------------| | | l r PopBoth | | |----------------------| | | l r PopBoth | | |----------------------| | | |r| | V | |l| |r| PopEither | Top |----------------------| Syntax here represented a syntax tree node. This structure was essentially two stacks that stored \u0026'a Syntax\u003c'a\u003e with a constraint that two objects must be popped together if they were pushed together (marked as PopBoth).\nI first refactored them into this form:\nstruct Vertex\u003c'a, 'b\u003e { // ... lhs_parents: Stack\u003cEnteredDelimiter\u003c'a\u003e\u003e, rhs_parents: Stack\u003cEnteredDelimiter\u003c'a\u003e\u003e, } enum EnteredDelimiter\u003c'a\u003e { PopEither(\u0026'a Syntax\u003c'a\u003e), PopBoth(\u0026'a Syntax\u003c'a\u003e), } | |PopEither(l)| |PopEither(r)| | |PopEither(l)| |PopEither(r)| | |PopEither(l)| | PopBoth(r) | | | PopBoth(l) | | PopBoth(r) | V | PopBoth(l) | |PopEither(r)| Top |PopEither(l)| |PopEither(r)| It was much more straightforward and consumed less memory. Then I noticed that each Syntax recorded its parent, we didn’t need to replicate this information in the stack (well, that was tricky as there were some edge cases). Therefore, the parent stack could be cropped to:\nstruct Vertex\u003c'a, 'b\u003e { // ... lhs_parents: Stack\u003cEnteredDelimiter\u003e, rhs_parents: Stack\u003cEnteredDelimiter\u003e, } enum EnteredDelimiter { PopEither, PopBoth, } | |PopEither| |PopEither| | |PopEither| |PopEither| | |PopEither| | PopBoth | | | PopBoth | | PopBoth | V | PopBoth | |PopEither| Top |PopEither| |PopEither| One layer of parents represented one layer of delimiters. It’s extremely rare to see 63 layers of delimiters. Besides, the search space of the algorithm is about O(num_syntax_nodes * 2 ^ stack_depth). When there are 64 layers of delimiters, the algorithm is unlikely to finish within a reasonable time and memory limit. Thus, I boldly compressed this stack into a bitmap.\nstruct Vertex\u003c'a, 'b\u003e { // ... lhs_parents: BitStack, rhs_parents: BitStack, } /// LSB is the stack top. One bit represents one `EnteredDelimiter`. /// /// Assume the underlying type is u8, then /// /// ```text /// new: 0b00000001 /// push x: 0b0000001x /// push y: 0b000001xy /// pop: 0b0000001x /// ``` struct BitStack(u64); #[repr(u64)] enum EnteredDelimiter { PopEither = 0, PopBoth = 1, } Here’s one thing to add: two vertices are different if they point to different Syntaxes or have different parent stacks. To distinguish between different vertices, we need to compare the whole stack. This is a high-frequency operation. Obviously, if two vertices have the same syntax nodes, then their parents must be equal. So comparing EnteredDelimiter sequence is enough. Under the bitmap representation, the whole stack can be compared in O(1) time.\nCan it be further optimized? Notice that in each movement, there’s at most one modification. Therefore, the parent stack pairs can be represented as a link to the previous Vertex + a modification:\nstruct Vertex\u003c'a, 'b\u003e { // ... last_vertex: Option\u003c\u0026'b Vertex\u003c'a, 'b\u003e\u003e, change: StackChange, } enum StackChange { PopEitherLhs, PopEitherRhs, PopBoth, None, } This structure can save 8 bytes from Vertex since Vertex has some unfilled padding space (7 bytes) to store the enum. However, it cannot be compared in O(1) time. For example:\nLast Vertex: Last Vertex: | |PopEither| |PopEither| | |PopEither| |PopEither| |PopEither| |PopEither| | |PopEither| | PopBoth | |PopEither| |PopEither| | |PopEither| | PopBoth | | PopBoth | | PopBoth | V | PopBoth | |PopEither| | PopBoth | | PopBoth | Top | PopBoth | |PopEither| |PopEither| |PopEither| Change: PopEitherLhs Change: PopEitherRhs They have identical stacks but different last_vertex and change. Also, this structure is hard to pop. But we’re close. There’s one exception: two identical stack pairs must have the same last_vertex if the change is PopBoth. So we can just record such a vertex and the number of PopEither in both sides.\nstruct Vertex\u003c'a, 'b\u003e { // ... pop_both_ancestor: Option\u003c\u0026'b Vertex\u003c'a, 'b\u003e\u003e, pop_lhs_cnt: u16, pop_rhs_cnt: u16, } | 3, 2, None | |PopEither| |PopEither| \u003c--+ | |PopEither| |PopEither| | | |PopEither| | | | | 0, 0, Some ---------+ | | PopBoth | | PopBoth | \u003c--+ | | | 1, 2, Some ---------+ | | PopBoth | | PopBoth | V |PopEither| |PopEither| Top |PopEither| This structure not only had O(1) comparison time but also saved 8 bytes per Vertex. And it relaxed the parent number limitation from 63 in total to u16::MAX consecutive PopEither, although 63 should be enough. All of its operations were just slightly more expensive than bitmaps or equally cheap. Lost efficiency could be won back by improved locality.\nTagged pointers Commits: d2f5e99, cb1c3e0\n\u0026Syntax must be aligned to size_of::() as Syntax contains usize fields, which means some of its low bits are always zeros. We can use these bits to store information such as an enum tag. On x86-64 and some other 64 bits platforms, the top 16 bits haven’t been used yet. We can store information there as well. But for portability, I didn’t use those top bits.\nBy the way, I wrote a crate called enum-ptr dedicated to this trick.\nSkip visited vertices Commits: 3612d08, 9e11a22\nIn Dijkstra’s Algorithm, once a vertex is extracted from the heap, its distance will not be relaxed anymore. A vertex might be pushed into the heap multiple times if it was relaxed multiple times and the heap is not capable of the decrease-key operation (see pairing heap and Fibonacci heap). We can mark a vertex as “visited” after it is popped and skip such vertices. We can also skip visited neighbors.\nBe aware that things can change if you’re using the A* Algorithm. If you are doing a graph search rather than a tree search, which is just the case of difftastic, and your heuristic is admissible but not consistent, then visited vertices should be marked as “not visited” after being relaxed. Besides, the radix heap will be unavailable since it requires the extracted elements follow a monotonic sequence.\nMy final code ran for ~280ms in the benchmark. Replacing the radix heap with std’s binary heap results in an extra ~20ms. A heuristic must bring more speedup than that while keeping admissible. This is challenging. I’ve tried several ideas but never succeeded.\nReserve memory Commits: b0ab6c8, 8625f62, 97e883d\nTrivial.\nReuse memory Commits: 8a0c82a\nAfter 9e11a22, neighbor nodes were no longer required to be stored in vertices. They could be simply thrown away after the loop. The code logic became: create a neighbor vector, find neighbors, and return that vector. Then the profile result showed that creating vectors took a noticeable amount of time. So I created a vector outside the loop and reuse it in each round. This saved numerous memory operations.\nExploit invariants Commits: 9f1a0ab, d2f5e99, 5e5eef2\nThe original Vertex was like:\npub struct Vertex\u003c'a, 'b\u003e { // ... pub lhs_syntax: Option\u003c\u0026'a Syntax\u003c'a\u003e\u003e, pub rhs_syntax: Option\u003c\u0026'a Syntax\u003c'a\u003e\u003e, lhs_parent_id: Option\u003cSyntaxId\u003e, rhs_parent_id: Option\u003cSyntaxId\u003e, } But I found that lhs/rhs_parent_id is Some only when lhs/rhs_syntax is None, respectively. Thus, they could be replaced by an enum and then compressed into a usize using the tagged pointer trick. This saved some instructions and memory footprint.\nLater, I found that during the entire shortest path finding procedure, the syntax tree was pinned. Thus, we didn’t need to obtain the unique SyntaxId at all. The pointer addresses were already unique. This further saved some instructions.\nPrune vertices Commits: 10ce859 to edc5516\nIt’s quite hard to explain this optimization in detail. It requires a deep understanding of the original implementation. I shall therefore simply introduce my ideas conceptually.\nIn brief, there were many vertices in the graph that held the following properties:\nOne can only go to another The edges between them are zero-weight. For example,\n--+ +--\u003e | | --+-\u003e (l0, r0) --[0]-\u003e (l1, r1) --[0]-\u003e (l2, r2) --+--\u003e | | --+ +--\u003e In this case, we can combine these vertices into one:\n--+ +--\u003e | | --+-\u003e (l012, r012) --+--\u003e | | --+ +--\u003e In the actual code, it’s more like “while there’s only one zero-weight edge, immediately move to the next vertex.”\nBy my estimation, this optimization shrank the search space by around 15%~25%, saving a huge amount of time and memory.\nManual inlining Commits: edc5516, adf6077\nC++ programmers are often taught that compilers make better decisions regarding whether functions should be inlined than they do. Because their lovely inline keyword can no longer affect inlining. However, there are a lot of factors to consider, some of which compiler doesn’t know. Inlining is not merely a matter of code size and call overhead.\nIt is preferable to inline frequently used functions rather than rarely used ones. Compiler doesn’t know which function is hot (unless PGO is used) but you know. Inlining enables more optimization opportunities. Because many optimizations cannot cross function boundaries, some of them heavily rely on inlining to bring cross-function code into their sight. Compiler cannot predict the outcome of inlining a function but you can (compile it multiple times). In Rust, inline does have effects, especially when crossing crate boundaries. Have a try: in my final code, removing #[inline(always)] from function next_vertex will increase the execution time by ~10%.\n","wordCount":"2511","inLanguage":"en","datePublished":"2022-10-06T00:00:00Z","dateModified":"2022-10-06T00:00:00Z","author":{"@type":"Person","name":"QuarticCat"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.quarticcat.com/posts/optimize-difftastic/"},"publisher":{"@type":"Organization","name":"QuarticCat's Blog","logo":{"@type":"ImageObject","url":"https://blog.quarticcat.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://blog.quarticcat.com/ accesskey=h title="Home (Alt + H)"><img src=https://blog.quarticcat.com/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://blog.quarticcat.com/zh/ title=中文 aria-label=中文>Zh</a></li></ul></div></div><ul id=menu><li><a href=https://blog.quarticcat.com/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://blog.quarticcat.com/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://blog.quarticcat.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://blog.quarticcat.com/blogroll/ title=Blogroll><span>Blogroll</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">How do I boost difftastic by 4x</h1><div class=post-meta><span title='2022-10-06 00:00:00 +0000 UTC'>October 6, 2022</span>&nbsp;·&nbsp;QuarticCat</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#how-does-difftastic-work>How does difftastic work</a></li><li><a href=#benchmarking--profiling>Benchmarking & profiling</a></li><li><a href=#optimizations>Optimizations</a><ul><li><a href=#free-lunch>Free lunch</a></li><li><a href=#simple-simplifications>Simple simplifications</a></li><li><a href=#refactor-parent-stack>Refactor parent stack</a></li><li><a href=#tagged-pointers>Tagged pointers</a></li><li><a href=#skip-visited-vertices>Skip visited vertices</a></li><li><a href=#reserve-memory>Reserve memory</a></li><li><a href=#reuse-memory>Reuse memory</a></li><li><a href=#exploit-invariants>Exploit invariants</a></li><li><a href=#prune-vertices>Prune vertices</a></li><li><a href=#manual-inlining>Manual inlining</a></li></ul></li></ul></nav></div></details></div><div class=post-content><p><a href=https://github.com/Wilfred/difftastic>Difftastic</a> is a structural diff that understands syntax. The diff results it generates are very fancy, but its performance is poor, and it consumes a lot of memory. Recently, I boosted it by 4x while using only 23% of memory (<a href=https://github.com/Wilfred/difftastic/pull/393>#393</a>, <a href=https://github.com/Wilfred/difftastic/pull/395>#395</a>, <a href=https://github.com/Wilfred/difftastic/pull/401>#401</a>). This post explains how I accomplished this. Hope it can bring you some inspiration.</p><p>When I started to write this post, not all optimizations were reviewed and merged. But I will keep it updated.</p><h2 id=how-does-difftastic-work>How does difftastic work<a hidden class=anchor aria-hidden=true href=#how-does-difftastic-work>#</a></h2><p>The official manual has a <a href=https://difftastic.wilfred.me.uk/diffing.html>chapter</a> describing its diff algorithm. Here&rsquo;s my understanding:</p><p>Say, we have two files. They are parsed to two syntax trees.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span>  -------------------------
</span></span><span style=display:flex><span>  - A         |  - A
</span></span><span style=display:flex><span>    - B       |    - B
</span></span><span style=display:flex><span>      - C     |    - D
</span></span><span style=display:flex><span>    - D       |      - E
</span></span><span style=display:flex><span>      - E     |      - F
</span></span></code></pre></div><p>We want to match them. To do this, we have two pointers to syntax nodes in two trees, respectively.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span>  -------------------------
</span></span><span style=display:flex><span>  - A  &lt;-     |  - A  &lt;-
</span></span><span style=display:flex><span>    - B       |    - B
</span></span><span style=display:flex><span>      - C     |    - D
</span></span><span style=display:flex><span>    - D       |      - E
</span></span><span style=display:flex><span>      - E     |      - F
</span></span></code></pre></div><p>In each step, we have some choices, and each of them represents a diff choice (an insertion, a deletion, unchanged, etc.). For example, here we can move both pointers by one node (pre-order traversal) since the nodes they point to are the same.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span>  - A
</span></span><span style=display:flex><span>  -------------------------
</span></span><span style=display:flex><span>    - B  &lt;-   |    - B  &lt;-
</span></span><span style=display:flex><span>      - C     |    - D
</span></span><span style=display:flex><span>    - D       |      - E
</span></span><span style=display:flex><span>      - E     |      - F
</span></span></code></pre></div><p>Or we can move the left pointer by one node, which means a deletion.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span><span style=color:#f92672>- - A
</span></span></span><span style=display:flex><span><span style=color:#f92672></span>  -------------------------
</span></span><span style=display:flex><span>    - B  &lt;-   |  - A  &lt;-
</span></span><span style=display:flex><span>      - C     |    - B
</span></span><span style=display:flex><span>    - D       |    - D
</span></span><span style=display:flex><span>      - E     |      - E
</span></span><span style=display:flex><span>              |      - F
</span></span></code></pre></div><p>Or we can move the right pointer by one node, which means an insertion.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span><span style=color:#a6e22e>+ - A
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>  -------------------------
</span></span><span style=display:flex><span>  - A  &lt;-     |    - B  &lt;-
</span></span><span style=display:flex><span>    - B       |    - D
</span></span><span style=display:flex><span>      - C     |      - E
</span></span><span style=display:flex><span>    - D       |      - F
</span></span><span style=display:flex><span>      - E     |
</span></span></code></pre></div><p>We keep moving pointers until finishing the traversal in both syntax trees. Then the moving path represents the diff result.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span>  - A
</span></span><span style=display:flex><span>    - B
</span></span><span style=display:flex><span><span style=color:#f92672>-     - C
</span></span></span><span style=display:flex><span><span style=color:#f92672></span>    - D
</span></span><span style=display:flex><span>      - E
</span></span><span style=display:flex><span><span style=color:#a6e22e>+     - F
</span></span></span></code></pre></div><p>Obviously, there are multiple paths. To find the best one, we abstract it as a shortest path problem: a vertex is a pointer pair, and an edge is a movement from one pointer pair to another. Edge lengths are manually defined based on our preferences. For example, it is preferable to see two identical nodes as unchanged rather than one insertion plus one deletion, therefore the length of the former is shorter.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>       +-[1]-&gt; (B, B) -&gt; ... --+
</span></span><span style=display:flex><span>       |                       |
</span></span><span style=display:flex><span>(A, A) +-[9]-&gt; (B, A) -&gt; ... --+-&gt; (EOF, EOF)
</span></span><span style=display:flex><span>       |                       |
</span></span><span style=display:flex><span>       +-[9]-&gt; (A, B) -&gt; ... --+
</span></span></code></pre></div><p>This is a simplified illustration. In the actual code, there are more kinds of edges, and the vertices contain more information.</p><p>You don&rsquo;t have to fully understand how it works internally to start optimizing. As long as your optimized code logically equals the previous one, it should be good. It is typical for your comprehension of the code to progressively advance throughout the optimization process. Of course, having a deeper understanding helps you identify more optimization opportunities.</p><h2 id=benchmarking--profiling>Benchmarking & profiling<a hidden class=anchor aria-hidden=true href=#benchmarking--profiling>#</a></h2><p>To perform optimization, you should first define a baseline, i.e., find a benchmark, and then profile it to locate hot spots and choose which code area merits your attention. Fortunately, the official manual also offers a <a href=https://difftastic.wilfred.me.uk/contributing.html#profiling>chapter</a> that covers all we need.</p><p>In addition, I used <a href=https://github.com/sharkdp/hyperfine>hyperfine</a> with some warm-up runs to improve the accuracy and stability of the result. Here&rsquo;s a <a href=https://llvm.org/docs/Benchmarking.html>document of LLVM</a> that introduces some tips to reduce benchmarking noise. I didn&rsquo;t use all of them at that time, because I just knew this webpage recently. :)</p><p>There are many excellent profiling tools. Examples include <a href=https://www.brendangregg.com/flamegraphs.html>flamegraph</a>, which can be used for more than just CPU metrics, and <a href=https://valgrind.org/>valgrind</a>, which is especially useful for memory profiling.</p><p>Apart from those fancy tools, you can try commenting out some code pieces or adding useless fields to structs and then check the performance difference. This will quickly give you a rough estimate of the amount of profit you will gain from optimizing them. Valueless targets are not worth your attention.</p><p>Another trick is that you can print something into stderr and then filter them by <code>&lt;command> >/dev/null 2>&amp;1</code>. Following that, you can do counting by <code>| wc -l</code>, or find the minimum / maximum value by <code>| sort -n | head/tail -1</code>. It&rsquo;s sometimes more convenient than implementing the same functionality inside the program. You can use this trick to collect information like how frequently the control flow enters a code block.</p><h2 id=optimizations>Optimizations<a hidden class=anchor aria-hidden=true href=#optimizations>#</a></h2><p>Here comes the main dish. I will select several commits and describe what I have done.</p><h3 id=free-lunch>Free lunch<a hidden class=anchor aria-hidden=true href=#free-lunch>#</a></h3><p><em>Commits:</em>
<a href=https://github.com/Wilfred/difftastic/pull/393/commits/06b46e935589117ac4583b6ca0d2a3020eb1c6b4><code>06b46e9</code></a></p><p>There are some free optimization approaches you can have a taste first. I call them &ldquo;free&rdquo; because applying them is effortless, you don&rsquo;t even have to know about the code.</p><ul><li><p>LTO: In Rust, this can be enabled by a single line in <code>Cargo.toml</code>: <code>lto = "thin"</code> or <code>"fat"</code>. As for C++, if you are using CMake, then passing <code>-DCMAKE_INTERPROCEDURAL_OPTIMIZATION=ON</code> should work.</p></li><li><p>PGO: For Rust, I recommend <a href=https://github.com/Kobzol/cargo-pgo>cargo-pgo</a>. For C++, you can follow instructions on <a href=https://clang.llvm.org/docs/UsersManual.html#profile-guided-optimization>Clang&rsquo;s doc</a>.</p></li><li><p><a href=https://github.com/llvm/llvm-project/blob/main/bolt/README.md>BOLT</a></p></li><li><p><a href=https://polly.llvm.org/>Polly</a></p></li><li><p>Memory Allocator: The default memory allocator usually performs badly. Better alternatives include {je,tc,mi,sn}malloc and maybe more.</p></li></ul><h3 id=simple-simplifications>Simple simplifications<a hidden class=anchor aria-hidden=true href=#simple-simplifications>#</a></h3><p><em>Commits:</em>
<a href=https://github.com/Wilfred/difftastic/pull/393/commits/d48ee2dfdb59e98c71ce8fd99933268a1eee56ee><code>d48ee2d</code></a>,
<a href=https://github.com/Wilfred/difftastic/pull/393/commits/3b0edb43a1f79637e7d85073d111239e49fd5034><code>3b0edb4</code></a>,
<a href=https://github.com/Wilfred/difftastic/pull/393/commits/b88625d09b9f2641dcd4519ce538aebe6f648322><code>b88625d</code></a></p><p>According to my profile results, most memory was used for storing the <code>Vertex</code> type. Any simplification of this type will result in a huge improvement. I discovered that one of its fields implemented <code>Copy</code> but was wrapped by <code>RefCell</code>, which was overkilled. <code>Cell</code> was just enough. Moreover, I found that the internal third-party <code>Stack</code> type had a lot of fields that were useless for this problem. It was a very simple functional stack, so I just wrote a new one to replace it.</p><h3 id=refactor-parent-stack>Refactor parent stack<a hidden class=anchor aria-hidden=true href=#refactor-parent-stack>#</a></h3><p><em>Commits:</em>
<a href=https://github.com/Wilfred/difftastic/pull/395/commits/2c6b7060a35a088e4a194fde4c51b18004f64c7f><code>2c6b706</code></a>,
<a href=https://github.com/Wilfred/difftastic/pull/401/commits/5e5eef231d2b3a65e303d16c47964e7fcd38322a><code>5e5eef2</code></a>,
<a href=https://github.com/Wilfred/difftastic/pull/401/commits/b95c3a6cf788c71bbfbb8ad58e295e88e56dd92d><code>b95c3a6</code></a></p><p>The original parent stack structure was obscure.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>Vertex</span><span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span>, <span style=color:#a6e22e>&#39;b</span><span style=color:#f92672>&gt;</span> {
</span></span><span style=display:flex><span>    <span style=color:#75715e>// ...
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    parents: <span style=color:#a6e22e>Stack</span><span style=color:#f92672>&lt;</span>EnteredDelimiter<span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span><span style=color:#f92672>&gt;&gt;</span>,
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>enum</span> <span style=color:#a6e22e>EnteredDelimiter</span><span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span><span style=color:#f92672>&gt;</span> {
</span></span><span style=display:flex><span>    PopEither((Stack<span style=color:#f92672>&lt;&amp;</span><span style=color:#a6e22e>&#39;a</span> Syntax<span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span><span style=color:#f92672>&gt;&gt;</span>, Stack<span style=color:#f92672>&lt;&amp;</span><span style=color:#a6e22e>&#39;a</span> Syntax<span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span><span style=color:#f92672>&gt;&gt;</span>)),
</span></span><span style=display:flex><span>    PopBoth((<span style=color:#f92672>&amp;</span><span style=color:#a6e22e>&#39;a</span> Syntax<span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span><span style=color:#f92672>&gt;</span>, <span style=color:#f92672>&amp;</span><span style=color:#a6e22e>&#39;a</span> Syntax<span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span><span style=color:#f92672>&gt;</span>)),
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>  |  |  |l|                 |
</span></span><span style=display:flex><span>  |  |  |l| |r|             |
</span></span><span style=display:flex><span>  |  |  |l| |r|  PopEither  |
</span></span><span style=display:flex><span>  |  |----------------------|
</span></span><span style=display:flex><span>  |  |   l   r    PopBoth   |
</span></span><span style=display:flex><span>  |  |----------------------|
</span></span><span style=display:flex><span>  |  |   l   r    PopBoth   |
</span></span><span style=display:flex><span>  |  |----------------------|
</span></span><span style=display:flex><span>  |  |      |r|             |
</span></span><span style=display:flex><span>  V  |  |l| |r|  PopEither  |
</span></span><span style=display:flex><span> Top |----------------------|
</span></span></code></pre></div><p><code>Syntax</code> here represented a syntax tree node. This structure was essentially two stacks that stored <code>&'a Syntax&lt;'a></code> with a constraint that two objects must be popped together if they were pushed together (marked as <code>PopBoth</code>).</p><p>I first refactored them into this form:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>Vertex</span><span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span>, <span style=color:#a6e22e>&#39;b</span><span style=color:#f92672>&gt;</span> {
</span></span><span style=display:flex><span>    <span style=color:#75715e>// ...
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    lhs_parents: <span style=color:#a6e22e>Stack</span><span style=color:#f92672>&lt;</span>EnteredDelimiter<span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span><span style=color:#f92672>&gt;&gt;</span>,
</span></span><span style=display:flex><span>    rhs_parents: <span style=color:#a6e22e>Stack</span><span style=color:#f92672>&lt;</span>EnteredDelimiter<span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span><span style=color:#f92672>&gt;&gt;</span>,
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>enum</span> <span style=color:#a6e22e>EnteredDelimiter</span><span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span><span style=color:#f92672>&gt;</span> {
</span></span><span style=display:flex><span>    PopEither(<span style=color:#f92672>&amp;</span><span style=color:#a6e22e>&#39;a</span> Syntax<span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span><span style=color:#f92672>&gt;</span>),
</span></span><span style=display:flex><span>    PopBoth(<span style=color:#f92672>&amp;</span><span style=color:#a6e22e>&#39;a</span> Syntax<span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span><span style=color:#f92672>&gt;</span>),
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>  |  |PopEither(l)| |PopEither(r)|
</span></span><span style=display:flex><span>  |  |PopEither(l)| |PopEither(r)|
</span></span><span style=display:flex><span>  |  |PopEither(l)| | PopBoth(r) |
</span></span><span style=display:flex><span>  |  | PopBoth(l) | | PopBoth(r) |
</span></span><span style=display:flex><span>  V  | PopBoth(l) | |PopEither(r)|
</span></span><span style=display:flex><span> Top |PopEither(l)| |PopEither(r)|
</span></span></code></pre></div><p>It was much more straightforward and consumed less memory. Then I noticed that each <code>Syntax</code> recorded its parent, we didn&rsquo;t need to replicate this information in the stack (well, that was tricky as there were some edge cases). Therefore, the parent stack could be cropped to:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>Vertex</span><span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span>, <span style=color:#a6e22e>&#39;b</span><span style=color:#f92672>&gt;</span> {
</span></span><span style=display:flex><span>    <span style=color:#75715e>// ...
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    lhs_parents: <span style=color:#a6e22e>Stack</span><span style=color:#f92672>&lt;</span>EnteredDelimiter<span style=color:#f92672>&gt;</span>,
</span></span><span style=display:flex><span>    rhs_parents: <span style=color:#a6e22e>Stack</span><span style=color:#f92672>&lt;</span>EnteredDelimiter<span style=color:#f92672>&gt;</span>,
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>enum</span> <span style=color:#a6e22e>EnteredDelimiter</span> {
</span></span><span style=display:flex><span>    PopEither,
</span></span><span style=display:flex><span>    PopBoth,
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>  |  |PopEither| |PopEither|
</span></span><span style=display:flex><span>  |  |PopEither| |PopEither|
</span></span><span style=display:flex><span>  |  |PopEither| | PopBoth |
</span></span><span style=display:flex><span>  |  | PopBoth | | PopBoth |
</span></span><span style=display:flex><span>  V  | PopBoth | |PopEither|
</span></span><span style=display:flex><span> Top |PopEither| |PopEither|
</span></span></code></pre></div><p>One layer of parents represented one layer of <a href=https://difftastic.wilfred.me.uk/glossary.html>delimiters</a>. It&rsquo;s extremely rare to see 63 layers of delimiters. Besides, the search space of the algorithm is about <code>O(num_syntax_nodes * 2 ^ stack_depth)</code>. When there are 64 layers of delimiters, the algorithm is unlikely to finish within a reasonable time and memory limit. Thus, I boldly compressed this stack into a bitmap.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>Vertex</span><span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span>, <span style=color:#a6e22e>&#39;b</span><span style=color:#f92672>&gt;</span> {
</span></span><span style=display:flex><span>    <span style=color:#75715e>// ...
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    lhs_parents: <span style=color:#a6e22e>BitStack</span>,
</span></span><span style=display:flex><span>    rhs_parents: <span style=color:#a6e22e>BitStack</span>,
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#e6db74>/// LSB is the stack top. One bit represents one `EnteredDelimiter`.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>///
</span></span></span><span style=display:flex><span><span style=color:#e6db74>/// Assume the underlying type is u8, then
</span></span></span><span style=display:flex><span><span style=color:#e6db74>///
</span></span></span><span style=display:flex><span><span style=color:#e6db74>/// ```text
</span></span></span><span style=display:flex><span><span style=color:#e6db74>/// new:      0b00000001
</span></span></span><span style=display:flex><span><span style=color:#e6db74>/// push x:   0b0000001x
</span></span></span><span style=display:flex><span><span style=color:#e6db74>/// push y:   0b000001xy
</span></span></span><span style=display:flex><span><span style=color:#e6db74>/// pop:      0b0000001x
</span></span></span><span style=display:flex><span><span style=color:#e6db74>/// ```
</span></span></span><span style=display:flex><span><span style=color:#e6db74></span><span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>BitStack</span>(<span style=color:#66d9ef>u64</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#[repr(u64)]</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>enum</span> <span style=color:#a6e22e>EnteredDelimiter</span> {
</span></span><span style=display:flex><span>    PopEither <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>    PopBoth <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Here&rsquo;s one thing to add: two vertices are different if they point to different <code>Syntax</code>es or have different parent stacks. To distinguish between different vertices, we need to compare the whole stack. This is a high-frequency operation. Obviously, if two vertices have the same syntax nodes, then their parents must be equal. So comparing <code>EnteredDelimiter</code> sequence is enough. Under the bitmap representation, the whole stack can be compared in O(1) time.</p><p>Can it be further optimized? Notice that in each movement, there&rsquo;s at most one modification. Therefore, the parent stack pairs can be represented as a link to the previous <code>Vertex</code> + a modification:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>Vertex</span><span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span>, <span style=color:#a6e22e>&#39;b</span><span style=color:#f92672>&gt;</span> {
</span></span><span style=display:flex><span>    <span style=color:#75715e>// ...
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    last_vertex: Option<span style=color:#f92672>&lt;&amp;</span><span style=color:#a6e22e>&#39;b</span> Vertex<span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span>, <span style=color:#a6e22e>&#39;b</span><span style=color:#f92672>&gt;&gt;</span>,
</span></span><span style=display:flex><span>    change: <span style=color:#a6e22e>StackChange</span>,
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>enum</span> <span style=color:#a6e22e>StackChange</span> {
</span></span><span style=display:flex><span>    PopEitherLhs,
</span></span><span style=display:flex><span>    PopEitherRhs,
</span></span><span style=display:flex><span>    PopBoth,
</span></span><span style=display:flex><span>    None,
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>This structure can save 8 bytes from <code>Vertex</code> since <code>Vertex</code> has some unfilled padding space (7 bytes) to store the enum. However, it cannot be compared in O(1) time. For example:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>          Last Vertex:              Last Vertex:
</span></span><span style=display:flex><span>  |              |PopEither|   |PopEither|
</span></span><span style=display:flex><span>  |  |PopEither| |PopEither|   |PopEither| |PopEither|
</span></span><span style=display:flex><span>  |  |PopEither| | PopBoth |   |PopEither| |PopEither|
</span></span><span style=display:flex><span>  |  |PopEither| | PopBoth |   | PopBoth | | PopBoth |
</span></span><span style=display:flex><span>  V  | PopBoth | |PopEither|   | PopBoth | | PopBoth |
</span></span><span style=display:flex><span> Top | PopBoth | |PopEither|   |PopEither| |PopEither|
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>       Change: PopEitherLhs      Change: PopEitherRhs
</span></span></code></pre></div><p>They have identical stacks but different <code>last_vertex</code> and <code>change</code>. Also, this structure is hard to pop. But we&rsquo;re close. There&rsquo;s one exception: two identical stack pairs must have the same <code>last_vertex</code> if the <code>change</code> is <code>PopBoth</code>. So we can just record such a vertex and the number of <code>PopEither</code> in both sides.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>Vertex</span><span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span>, <span style=color:#a6e22e>&#39;b</span><span style=color:#f92672>&gt;</span> {
</span></span><span style=display:flex><span>    <span style=color:#75715e>// ...
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    pop_both_ancestor: Option<span style=color:#f92672>&lt;&amp;</span><span style=color:#a6e22e>&#39;b</span> Vertex<span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span>, <span style=color:#a6e22e>&#39;b</span><span style=color:#f92672>&gt;&gt;</span>,
</span></span><span style=display:flex><span>    pop_lhs_cnt: <span style=color:#66d9ef>u16</span>,
</span></span><span style=display:flex><span>    pop_rhs_cnt: <span style=color:#66d9ef>u16</span>,
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>  |         3, 2, None
</span></span><span style=display:flex><span>  |  |PopEither| |PopEither| &lt;--+
</span></span><span style=display:flex><span>  |  |PopEither| |PopEither|    |
</span></span><span style=display:flex><span>  |  |PopEither|                |
</span></span><span style=display:flex><span>  |                             |
</span></span><span style=display:flex><span>  |         0, 0, Some ---------+
</span></span><span style=display:flex><span>  |  | PopBoth | | PopBoth | &lt;--+
</span></span><span style=display:flex><span>  |                             |
</span></span><span style=display:flex><span>  |         1, 2, Some ---------+
</span></span><span style=display:flex><span>  |  | PopBoth | | PopBoth |
</span></span><span style=display:flex><span>  V  |PopEither| |PopEither|
</span></span><span style=display:flex><span> Top             |PopEither|
</span></span></code></pre></div><p>This structure not only had O(1) comparison time but also saved 8 bytes per <code>Vertex</code>. And it relaxed the parent number limitation from 63 in total to <code>u16::MAX</code> consecutive <code>PopEither</code>, although 63 should be enough. All of its operations were just slightly more expensive than bitmaps or equally cheap. Lost efficiency could be won back by improved locality.</p><h3 id=tagged-pointers>Tagged pointers<a hidden class=anchor aria-hidden=true href=#tagged-pointers>#</a></h3><p><em>Commits:</em>
<a href=https://github.com/Wilfred/difftastic/pull/395/commits/d2f5e996b60465ee866ae13677930328740a14b3><code>d2f5e99</code></a>,
<a href=https://github.com/Wilfred/difftastic/pull/395/commits/cb1c3e0ea38d31735b3f5433fe6582c137b22a2f><code>cb1c3e0</code></a></p><p><code>&amp;Syntax</code> must be aligned to <code>size_of::&lt;usize>()</code> as <code>Syntax</code> contains <code>usize</code> fields, which means some of its low bits are always zeros. We can use these bits to store information such as an enum tag. On x86-64 and some other 64 bits platforms, the top 16 bits haven&rsquo;t been used yet. We can store information there as well. But for portability, I didn&rsquo;t use those top bits.</p><p>By the way, I wrote a crate called <a href=https://github.com/QuarticCat/enum-ptr>enum-ptr</a> dedicated to this trick.</p><h3 id=skip-visited-vertices>Skip visited vertices<a hidden class=anchor aria-hidden=true href=#skip-visited-vertices>#</a></h3><p><em>Commits:</em>
<a href=https://github.com/Wilfred/difftastic/pull/395/commits/3612d0844af5928416c2237e57a0c9ad000a0ceb><code>3612d08</code></a>,
<a href=https://github.com/Wilfred/difftastic/pull/395/commits/9e11a2213ff9168500389145f34a6784dea9e89b><code>9e11a22</code></a></p><p>In Dijkstra&rsquo;s Algorithm, once a vertex is extracted from the heap, its distance will not be relaxed anymore. A vertex might be pushed into the heap multiple times if it was relaxed multiple times and the heap is not capable of the decrease-key operation (see pairing heap and Fibonacci heap). We can mark a vertex as &ldquo;visited&rdquo; after it is popped and skip such vertices. We can also skip visited neighbors.</p><p>Be aware that things can change if you&rsquo;re using the A* Algorithm. If you are doing a graph search rather than a tree search, which is just the case of difftastic, and your heuristic is admissible but not consistent, then visited vertices should be marked as &ldquo;not visited&rdquo; after being relaxed. Besides, the radix heap will be unavailable since it requires the extracted elements follow a monotonic sequence.</p><p>My final code ran for ~280ms in the benchmark. Replacing the radix heap with std&rsquo;s binary heap results in an extra ~20ms. A heuristic must bring more speedup than that while keeping admissible. This is challenging. I&rsquo;ve tried several ideas but never succeeded.</p><h3 id=reserve-memory>Reserve memory<a hidden class=anchor aria-hidden=true href=#reserve-memory>#</a></h3><p><em>Commits:</em>
<a href=https://github.com/Wilfred/difftastic/pull/395/commits/b0ab6c899a369cab73d79304002563fe08bae10d><code>b0ab6c8</code></a>,
<a href=https://github.com/Wilfred/difftastic/pull/401/commits/8625f620af2c09390f2bde43bb9e8f7508afc8e6><code>8625f62</code></a>,
<a href=https://github.com/Wilfred/difftastic/pull/401/commits/97e883dd5fb263d5d91bb8edbf0618347b66557e><code>97e883d</code></a></p><p>Trivial.</p><h3 id=reuse-memory>Reuse memory<a hidden class=anchor aria-hidden=true href=#reuse-memory>#</a></h3><p><em>Commits:</em>
<a href=https://github.com/Wilfred/difftastic/pull/401/commits/8a0c82ad623121d63cafeae7eedb3c0471861e7a><code>8a0c82a</code></a></p><p>After <code>9e11a22</code>, neighbor nodes were no longer required to be stored in vertices. They could be simply thrown away after the loop. The code logic became: create a neighbor vector, find neighbors, and return that vector. Then the profile result showed that creating vectors took a noticeable amount of time. So I created a vector outside the loop and reuse it in each round. This saved numerous memory operations.</p><h3 id=exploit-invariants>Exploit invariants<a hidden class=anchor aria-hidden=true href=#exploit-invariants>#</a></h3><p><em>Commits:</em>
<a href=https://github.com/Wilfred/difftastic/pull/395/commits/9f1a0ab1e606e7f32c22d42b6652555426c7b1fc><code>9f1a0ab</code></a>,
<a href=https://github.com/Wilfred/difftastic/pull/395/commits/d2f5e996b60465ee866ae13677930328740a14b3><code>d2f5e99</code></a>,
<a href=https://github.com/Wilfred/difftastic/pull/401/commits/5e5eef231d2b3a65e303d16c47964e7fcd38322a><code>5e5eef2</code></a></p><p>The original <code>Vertex</code> was like:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#66d9ef>pub</span> <span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>Vertex</span><span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span>, <span style=color:#a6e22e>&#39;b</span><span style=color:#f92672>&gt;</span> {
</span></span><span style=display:flex><span>    <span style=color:#75715e>// ...
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>pub</span> lhs_syntax: Option<span style=color:#f92672>&lt;&amp;</span><span style=color:#a6e22e>&#39;a</span> Syntax<span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span><span style=color:#f92672>&gt;&gt;</span>,
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>pub</span> rhs_syntax: Option<span style=color:#f92672>&lt;&amp;</span><span style=color:#a6e22e>&#39;a</span> Syntax<span style=color:#f92672>&lt;</span><span style=color:#a6e22e>&#39;a</span><span style=color:#f92672>&gt;&gt;</span>,
</span></span><span style=display:flex><span>    lhs_parent_id: Option<span style=color:#f92672>&lt;</span>SyntaxId<span style=color:#f92672>&gt;</span>,
</span></span><span style=display:flex><span>    rhs_parent_id: Option<span style=color:#f92672>&lt;</span>SyntaxId<span style=color:#f92672>&gt;</span>,
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>But I found that <code>lhs/rhs_parent_id</code> is <code>Some</code> only when <code>lhs/rhs_syntax</code> is <code>None</code>, respectively. Thus, they could be replaced by an enum and then compressed into a <code>usize</code> using the tagged pointer trick. This saved some instructions and memory footprint.</p><p>Later, I found that during the entire shortest path finding procedure, the syntax tree was pinned. Thus, we didn&rsquo;t need to obtain the unique <code>SyntaxId</code> at all. The pointer addresses were already unique. This further saved some instructions.</p><h3 id=prune-vertices>Prune vertices<a hidden class=anchor aria-hidden=true href=#prune-vertices>#</a></h3><p><em>Commits:</em>
<a href=https://github.com/Wilfred/difftastic/pull/401/commits/10ce859bf4c465e3d32fa909c4f6150282910c05><code>10ce859</code></a>
to
<a href=https://github.com/Wilfred/difftastic/pull/401/commits/edc5516eb90cc6c638e77140f2ec674378c04a73><code>edc5516</code></a></p><p>It&rsquo;s quite hard to explain this optimization in detail. It requires a deep understanding of the original implementation. I shall therefore simply introduce my ideas conceptually.</p><p>In brief, there were many vertices in the graph that held the following properties:</p><ul><li>One can only go to another</li><li>The edges between them are zero-weight.</li></ul><p>For example,</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>--+                                                +--&gt;
</span></span><span style=display:flex><span>  |                                                |
</span></span><span style=display:flex><span>--+-&gt; (l0, r0) --[0]-&gt; (l1, r1) --[0]-&gt; (l2, r2) --+--&gt;
</span></span><span style=display:flex><span>  |                                                |
</span></span><span style=display:flex><span>--+                                                +--&gt;
</span></span></code></pre></div><p>In this case, we can combine these vertices into one:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>--+                  +--&gt;
</span></span><span style=display:flex><span>  |                  |
</span></span><span style=display:flex><span>--+-&gt; (l012, r012) --+--&gt;
</span></span><span style=display:flex><span>  |                  |
</span></span><span style=display:flex><span>--+                  +--&gt;
</span></span></code></pre></div><p>In the actual code, it&rsquo;s more like &ldquo;while there&rsquo;s only one zero-weight edge, immediately move to the next vertex.&rdquo;</p><p>By my estimation, this optimization shrank the search space by around 15%~25%, saving a huge amount of time and memory.</p><h3 id=manual-inlining>Manual inlining<a hidden class=anchor aria-hidden=true href=#manual-inlining>#</a></h3><p><em>Commits:</em>
<a href=https://github.com/Wilfred/difftastic/pull/401/commits/edc5516eb90cc6c638e77140f2ec674378c04a73><code>edc5516</code></a>,
<a href=https://github.com/Wilfred/difftastic/pull/401/commits/adf6077f6f5719d48c2a9fcabcabc2c9af68f48f><code>adf6077</code></a></p><p>C++ programmers are often taught that compilers make better decisions regarding whether functions should be inlined than they do. Because their lovely <code>inline</code> keyword can no longer affect inlining. However, there are a lot of factors to consider, some of which compiler doesn&rsquo;t know. Inlining is not merely a matter of code size and call overhead.</p><ul><li>It is preferable to inline frequently used functions rather than rarely used ones. Compiler doesn&rsquo;t know which function is hot (unless PGO is used) but you know.</li><li>Inlining enables more optimization opportunities. Because many optimizations cannot cross function boundaries, some of them heavily rely on inlining to bring cross-function code into their sight. Compiler cannot predict the outcome of inlining a function but you can (compile it multiple times).</li><li>In Rust, <code>inline</code> does have effects, especially when crossing crate boundaries.</li></ul><p>Have a try: in my final code, removing <code>#[inline(always)]</code> from function <code>next_vertex</code> will increase the execution time by ~10%.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://blog.quarticcat.com/tags/rust/>Rust</a></li><li><a href=https://blog.quarticcat.com/tags/optimization/>Optimization</a></li></ul><nav class=paginav><a class=prev href=https://blog.quarticcat.com/posts/some-useful-zsh-key-bindings/><span class=title>« Prev</span><br><span>Some useful Zsh key-bindings</span>
</a><a class=next href=https://blog.quarticcat.com/posts/rvv-may-not-be-as-good-as-you-think/><span class=title>Next »</span><br><span>RVV may not be as good as you think</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://blog.quarticcat.com/>QuarticCat's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>